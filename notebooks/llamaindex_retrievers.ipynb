{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a80c1ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All imports successful!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import List, Optional\n",
    "import asyncio\n",
    "import warnings\n",
    "import numpy as np\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Core LlamaIndex imports\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex, \n",
    "    SimpleDirectoryReader, \n",
    "    Document,\n",
    "    Settings,\n",
    "    DocumentSummaryIndex,\n",
    "    KeywordTableIndex\n",
    ")\n",
    "from llama_index.core.retrievers import (\n",
    "    BaseRetriever,\n",
    "    VectorIndexRetriever,\n",
    "    AutoMergingRetriever,\n",
    "    RecursiveRetriever,\n",
    "    QueryFusionRetriever\n",
    ")\n",
    "from llama_index.core.indices.document_summary import (\n",
    "    DocumentSummaryIndexLLMRetriever,\n",
    "    DocumentSummaryIndexEmbeddingRetriever,\n",
    ")\n",
    "from llama_index.core.node_parser import SentenceSplitter, HierarchicalNodeParser\n",
    "from llama_index.core.schema import NodeWithScore, QueryBundle\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.postprocessor import SentenceTransformerRerank\n",
    "from llama_index.core.embeddings import BaseEmbedding\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "# Advanced retriever imports\n",
    "from llama_index.retrievers.bm25 import BM25Retriever\n",
    "\n",
    "# Sentence transformers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Statistical libraries for fusion techniques\n",
    "try:\n",
    "    from scipy import stats\n",
    "    SCIPY_AVAILABLE = True\n",
    "except ImportError:\n",
    "    SCIPY_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è scipy not available - some advanced fusion features will be limited\")\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0ad2fb",
   "metadata": {},
   "source": [
    "## llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1820655",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama.chat_models import ChatOllama\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import HumanMessage, ToolMessage, AIMessage\n",
    "import os\n",
    "from typing import Literal\n",
    "from datetime import datetime\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "OLLAMA_CLIENT_BASE_URL = \"http://localhost:11434\"\n",
    "\n",
    "# --- Initialize ChatOllama instance ---\n",
    "# This is your main LLM instance that will be used for both direct queries and tool calls.\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3.1:latest\", # Ensure this model is pulled on your remote Ollama server\n",
    "    temperature=0.0,\n",
    "    base_url=OLLAMA_CLIENT_BASE_URL, # Crucial: points to your accessible remote server (via tunnel) [1, 2]\n",
    "    api_key=\"ollama\" # Dummy value, as Ollama doesn't use API keys\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8dba530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Initializing HuggingFace embeddings...\n",
      "‚úÖ HuggingFace embeddings initialized!\n"
     ]
    }
   ],
   "source": [
    "print(\"üîß Initializing HuggingFace embeddings...\")\n",
    "embed_model = HuggingFaceEmbedding(\n",
    "    model_name=\"BAAI/bge-small-en-v1.5\"\n",
    ")\n",
    "print(\"‚úÖ HuggingFace embeddings initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb121036",
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10aa76ba",
   "metadata": {},
   "source": [
    "Advanced retrievers in LlamaIndex are sophisticated components that go beyond simple vector similarity search to provide more nuanced, context-aware, and intelligent information retrieval. They combine multiple techniques such as:\n",
    "\n",
    "- **Semantic Understanding**: Using embeddings to understand meaning and context\n",
    "- **Keyword Matching**: Precise term-based search for exact specifications\n",
    "- **Hierarchical Context**: Maintaining relationships between different levels of information\n",
    "- **Multi-Query Processing**: Generating and combining results from multiple query variations\n",
    "- **Fusion Techniques**: Intelligently combining results from different retrieval methods\n",
    "\n",
    "### Why are Advanced Retrievers Important?\n",
    "\n",
    "1. **Improved Accuracy**: Advanced retrievers can find more relevant information by using multiple search strategies\n",
    "2. **Better Context Preservation**: They maintain important relationships between pieces of information\n",
    "3. **Reduced Hallucination**: More precise retrieval leads to more accurate AI responses\n",
    "4. **Scalability**: Efficient retrieval strategies work better with large document collections\n",
    "5. **Flexibility**: Different retrieval methods can be combined for optimal results\n",
    "\n",
    "### Index Types Overview\n",
    "\n",
    "Before exploring advanced retrievers, it's helpful to first understand the three main index types supported by LlamaIndex. Each is designed to support different retrieval scenarios:\n",
    "\n",
    "**VectorStoreIndex:**\n",
    "- Stores vector embeddings for each document chunk\n",
    "- Best suited for semantic retrieval based on meaning\n",
    "- Commonly used in LLM pipelines and RAG applications\n",
    "\n",
    "**DocumentSummaryIndex:**\n",
    "- Generates and stores summaries of documents at indexing time\n",
    "- Uses summaries to filter documents before retrieving full content\n",
    "- Especially useful for large and diverse document sets that cannot fit in the context window of an LLM\n",
    "\n",
    "**KeywordTableIndex:**\n",
    "- Extracts keywords from documents and maps them to specific content chunks\n",
    "- Enables exact keyword matching for rule-based or hybrid search scenarios\n",
    "- Ideal for applications requiring precise term matching\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd9095bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loaded 10 sample documents\n",
      " Prepared 7 consistent demo queries\n",
      "1. Machine learning is a subset of artificial intelligence that focuses on algorithms that can learn from data.\n",
      "2. Deep learning uses neural networks with multiple layers to model and understand complex patterns in data.\n",
      "3. Natural language processing enables computers to understand, interpret, and generate human language.\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# Sample data for the lab - AI/ML focused documents\n",
    "SAMPLE_DOCUMENTS = [\n",
    "    \"Machine learning is a subset of artificial intelligence that focuses on algorithms that can learn from data.\",\n",
    "    \"Deep learning uses neural networks with multiple layers to model and understand complex patterns in data.\",\n",
    "    \"Natural language processing enables computers to understand, interpret, and generate human language.\",\n",
    "    \"Computer vision allows machines to interpret and understand visual information from the world.\",\n",
    "    \"Reinforcement learning is a type of machine learning where agents learn to make decisions through rewards and penalties.\",\n",
    "    \"Supervised learning uses labeled training data to learn a mapping from inputs to outputs.\",\n",
    "    \"Unsupervised learning finds hidden patterns in data without labeled examples.\",\n",
    "    \"Transfer learning leverages knowledge from pre-trained models to improve performance on new tasks.\",\n",
    "    \"Generative AI can create new content including text, images, code, and more.\",\n",
    "    \"Large language models are trained on vast amounts of text data to understand and generate human-like text.\"\n",
    "]\n",
    "\n",
    "# Consistent query examples used throughout the lab\n",
    "DEMO_QUERIES = {\n",
    "    \"basic\": \"What is machine learning?\",\n",
    "    \"technical\": \"neural networks deep learning\", \n",
    "    \"learning_types\": \"different types of learning\",\n",
    "    \"advanced\": \"How do neural networks work in deep learning?\",\n",
    "    \"applications\": \"What are the applications of AI?\",\n",
    "    \"comprehensive\": \"What are the main approaches to machine learning?\",\n",
    "    \"specific\": \"supervised learning techniques\"\n",
    "}\n",
    "\n",
    "print(f\" Loaded {len(SAMPLE_DOCUMENTS)} sample documents\")\n",
    "print(f\" Prepared {len(DEMO_QUERIES)} consistent demo queries\")\n",
    "for i, doc in enumerate(SAMPLE_DOCUMENTS[:3], 1):\n",
    "    print(f\"{i}. {doc}\")\n",
    "print(\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb07783d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Initializing Advanced Retrievers Lab...\n",
      "üìä Creating indexes...\n",
      "current doc id: 8f64bd78-64cf-4ccb-8f6d-66a641a1bb79\n",
      "current doc id: 3fa23e5c-271c-4351-9368-0c7d914a977e\n",
      "current doc id: cbc4dce2-8bbe-4295-8bbc-730f37931944\n",
      "current doc id: 01e06f81-ee8c-490d-9e0d-c27872d8a6db\n",
      "current doc id: 715b64a5-816e-4294-a044-e261bd6f007b\n",
      "current doc id: 915283a1-bda1-4475-9e7f-4ec140d9091c\n",
      "current doc id: e6e19497-82f9-4cca-9045-ab127cc2fce8\n",
      "current doc id: 1bb7c092-e626-41d2-8635-1c9f198b3e26\n",
      "current doc id: 3bc16a77-f3a1-4a87-9258-8ec3961a1753\n",
      "current doc id: c23c7b07-58a7-4e1a-b20f-a2b40d14ff97\n",
      "‚úÖ Advanced Retrievers Lab Initialized!\n",
      "üìÑ Loaded 10 documents\n",
      "üî¢ Created 10 nodes\n"
     ]
    }
   ],
   "source": [
    "class AdvancedRetrieversLab:\n",
    "    def __init__(self):\n",
    "        print(\"üöÄ Initializing Advanced Retrievers Lab...\")\n",
    "        self.documents = [Document(text=text) for text in SAMPLE_DOCUMENTS]\n",
    "        self.nodes = SentenceSplitter().get_nodes_from_documents(self.documents)\n",
    "        \n",
    "        print(\"üìä Creating indexes...\")\n",
    "        # Create various indexes\n",
    "        self.vector_index = VectorStoreIndex.from_documents(self.documents)\n",
    "        self.document_summary_index = DocumentSummaryIndex.from_documents(self.documents)\n",
    "        self.keyword_index = KeywordTableIndex.from_documents(self.documents)\n",
    "        \n",
    "        print(\"‚úÖ Advanced Retrievers Lab Initialized!\")\n",
    "        print(f\"üìÑ Loaded {len(self.documents)} documents\")\n",
    "        print(f\"üî¢ Created {len(self.nodes)} nodes\")\n",
    "\n",
    "# Initialize the lab\n",
    "lab = AdvancedRetrieversLab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf3b13e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "1. VECTOR INDEX RETRIEVER\n",
      "============================================================\n",
      "Query: What is machine learning?\n",
      "Retrieved 3 nodes:\n",
      "1. Score: 0.8700\n",
      "   Text: Machine learning is a subset of artificial intelligence that focuses on algorithms that can learn fr...\n",
      "\n",
      "2. Score: 0.7644\n",
      "   Text: Reinforcement learning is a type of machine learning where agents learn to make decisions through re...\n",
      "\n",
      "3. Score: 0.6979\n",
      "   Text: Supervised learning uses labeled training data to learn a mapping from inputs to outputs....\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"1. VECTOR INDEX RETRIEVER\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Basic vector retriever\n",
    "vector_retriever = VectorIndexRetriever(\n",
    "    index=lab.vector_index,\n",
    "    similarity_top_k=3\n",
    ")\n",
    "\n",
    "# Alternative creation method\n",
    "alt_retriever = lab.vector_index.as_retriever(similarity_top_k=3)\n",
    "\n",
    "query = DEMO_QUERIES[\"basic\"]  # \"What is machine learning?\"\n",
    "nodes = vector_retriever.retrieve(query)\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"Retrieved {len(nodes)} nodes:\")\n",
    "for i, node in enumerate(nodes, 1):\n",
    "    print(f\"{i}. Score: {node.score:.4f}\")\n",
    "    print(f\"   Text: {node.text[:100]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "898dc908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "2. BM25 RETRIEVER\n",
      "============================================================\n",
      "Query: neural networks deep learning\n",
      "BM25 analyzes exact keyword matches with sophisticated scoring\n",
      "Retrieved 3 nodes:\n",
      "1. BM25 Score: 2.5203\n",
      "   Text: Deep learning uses neural networks with multiple layers to model and understand complex patterns in ...\n",
      "   ‚Üí Found terms: ['neural', 'networks', 'deep', 'learning']\n",
      "\n",
      "2. BM25 Score: 0.3372\n",
      "   Text: Reinforcement learning is a type of machine learning where agents learn to make decisions through re...\n",
      "   ‚Üí Found terms: ['learning']\n",
      "\n",
      "3. BM25 Score: 0.3024\n",
      "   Text: Machine learning is a subset of artificial intelligence that focuses on algorithms that can learn fr...\n",
      "   ‚Üí Found terms: ['learning']\n",
      "\n",
      "BM25 vs TF-IDF Comparison:\n",
      "TF-IDF Problem: Linear term frequency scaling\n",
      "  Example: 10 occurrences ‚Üí score of 10, 100 occurrences ‚Üí score of 100\n",
      "BM25 Solution: Saturation function\n",
      "  Example: 10 occurrences ‚Üí high score, 100 occurrences ‚Üí slightly higher score\n",
      "\n",
      "TF-IDF Problem: No document length consideration\n",
      "  Example: Long documents dominate results\n",
      "BM25 Solution: Length normalization (b parameter)\n",
      "  Example: Scores adjusted based on document length vs. average\n",
      "\n",
      "Key BM25 Parameters:\n",
      "- k1 ‚âà 1.2: Term frequency saturation (how quickly scores plateau)\n",
      "- b ‚âà 0.75: Document length normalization (0=none, 1=full)\n",
      "- IDF weighting: Rare terms get higher scores\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"2. BM25 RETRIEVER\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    import Stemmer\n",
    "    \n",
    "    # Create BM25 retriever with default parameters\n",
    "    bm25_retriever = BM25Retriever.from_defaults(\n",
    "        nodes=lab.nodes,\n",
    "        similarity_top_k=3,\n",
    "        stemmer=Stemmer.Stemmer(\"english\"),\n",
    "        language=\"english\"\n",
    "    )\n",
    "    \n",
    "    query = DEMO_QUERIES[\"technical\"]  # \"neural networks deep learning\"\n",
    "    nodes = bm25_retriever.retrieve(query)\n",
    "    \n",
    "    print(f\"Query: {query}\")\n",
    "    print(\"BM25 analyzes exact keyword matches with sophisticated scoring\")\n",
    "    print(f\"Retrieved {len(nodes)} nodes:\")\n",
    "    \n",
    "    for i, node in enumerate(nodes, 1):\n",
    "        score = node.score if hasattr(node, 'score') and node.score else 0\n",
    "        print(f\"{i}. BM25 Score: {score:.4f}\")\n",
    "        print(f\"   Text: {node.text[:100]}...\")\n",
    "        \n",
    "        # Highlight which query terms appear in the text\n",
    "        text_lower = node.text.lower()\n",
    "        query_terms = query.lower().split()\n",
    "        found_terms = [term for term in query_terms if term in text_lower]\n",
    "        if found_terms:\n",
    "            print(f\"   ‚Üí Found terms: {found_terms}\")\n",
    "        print()\n",
    "    \n",
    "    print(\"BM25 vs TF-IDF Comparison:\")\n",
    "    print(\"TF-IDF Problem: Linear term frequency scaling\")\n",
    "    print(\"  Example: 10 occurrences ‚Üí score of 10, 100 occurrences ‚Üí score of 100\")\n",
    "    print(\"BM25 Solution: Saturation function\")\n",
    "    print(\"  Example: 10 occurrences ‚Üí high score, 100 occurrences ‚Üí slightly higher score\")\n",
    "    print()\n",
    "    print(\"TF-IDF Problem: No document length consideration\")\n",
    "    print(\"  Example: Long documents dominate results\")\n",
    "    print(\"BM25 Solution: Length normalization (b parameter)\")\n",
    "    print(\"  Example: Scores adjusted based on document length vs. average\")\n",
    "    print()\n",
    "    print(\"Key BM25 Parameters:\")\n",
    "    print(\"- k1 ‚âà 1.2: Term frequency saturation (how quickly scores plateau)\")\n",
    "    print(\"- b ‚âà 0.75: Document length normalization (0=none, 1=full)\")\n",
    "    print(\"- IDF weighting: Rare terms get higher scores\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è BM25Retriever requires 'pip install PyStemmer'\")\n",
    "    print(\"Demonstrating BM25 concepts with fallback vector search...\")\n",
    "    \n",
    "    fallback_retriever = lab.vector_index.as_retriever(similarity_top_k=3)\n",
    "    query = DEMO_QUERIES[\"technical\"]\n",
    "    nodes = fallback_retriever.retrieve(query)\n",
    "    \n",
    "    print(f\"Query: {query}\")\n",
    "    print(\"(Using vector fallback to demonstrate BM25 concepts)\")\n",
    "    \n",
    "    for i, node in enumerate(nodes, 1):\n",
    "        print(f\"{i}. Vector Score: {node.score:.4f}\")\n",
    "        print(f\"   Text: {node.text[:100]}...\")\n",
    "        \n",
    "        # Demonstrate TF-IDF concept manually\n",
    "        text_lower = node.text.lower()\n",
    "        query_terms = query.lower().split()\n",
    "        found_terms = [term for term in query_terms if term in text_lower]\n",
    "        \n",
    "        if found_terms:\n",
    "            print(f\"   ‚Üí BM25 would boost this result for terms: {found_terms}\")\n",
    "        print()\n",
    "    \n",
    "    print(\"BM25 Concept Demonstration:\")\n",
    "    print(\"1. TF-IDF Foundation:\")\n",
    "    print(\"   - Term Frequency: How often words appear in document\")\n",
    "    print(\"   - Inverse Document Frequency: How rare words are across collection\")\n",
    "    print(\"   - TF-IDF = TF √ó IDF (balances frequency vs rarity)\")\n",
    "    print()\n",
    "    print(\"2. BM25 Improvements:\")\n",
    "    print(\"   - Saturation: Prevents over-scoring repeated terms\")\n",
    "    print(\"   - Length normalization: Prevents long document bias\")\n",
    "    print(\"   - Tunable parameters: k1 (saturation) and b (length adjustment)\")\n",
    "    print()\n",
    "    print(\"3. Real-world Usage:\")\n",
    "    print(\"   - Elasticsearch default scoring function\")\n",
    "    print(\"   - Apache Lucene/Solr standard\")\n",
    "    print(\"   - Used in 83% of text-based recommender systems\")\n",
    "    print(\"   - Developed by Robertson & Sp√§rck Jones at City University London\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edeff2d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5752864",
   "metadata": {},
   "source": [
    "## 3. Document Summary Index Retrievers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "220099d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "3. DOCUMENT SUMMARY INDEX RETRIEVERS\n",
      "============================================================\n",
      "Query: different types of learning\n",
      "\n",
      "A) LLM-based Document Summary Retriever:\n",
      "Uses LLM to select relevant documents based on summaries\n",
      "Retrieved 3 nodes\n",
      "1. Score: 9.0000\n",
      "   Text: Supervised learning uses labeled training data to learn a mapping from inputs to...\n",
      "\n",
      "2. Score: 8.0000\n",
      "   Text: Machine learning is a subset of artificial intelligence that focuses on algorith...\n",
      "\n",
      "B) Embedding-based Document Summary Retriever:\n",
      "Uses vector similarity between query and document summaries\n",
      "Retrieved 3 nodes\n",
      "1. (Document summary)\n",
      "   Text: Supervised learning uses labeled training data to learn a mapping from inputs to...\n",
      "\n",
      "2. (Document summary)\n",
      "   Text: Unsupervised learning finds hidden patterns in data without labeled examples....\n",
      "\n",
      "Document Summary Index workflow:\n",
      "1. Generates summaries for each document using LLM\n",
      "2. Uses summaries to select relevant documents\n",
      "3. Returns full content from selected documents\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"3. DOCUMENT SUMMARY INDEX RETRIEVERS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# LLM-based document summary retriever\n",
    "doc_summary_retriever_llm = DocumentSummaryIndexLLMRetriever(\n",
    "    lab.document_summary_index,\n",
    "    choice_top_k=3  # Number of documents to select\n",
    ")\n",
    "\n",
    "# Embedding-based document summary retriever  \n",
    "doc_summary_retriever_embedding = DocumentSummaryIndexEmbeddingRetriever(\n",
    "    lab.document_summary_index,\n",
    "    similarity_top_k=3  # Number of documents to select\n",
    ")\n",
    "\n",
    "query = DEMO_QUERIES[\"learning_types\"]  # \"different types of learning\"\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "\n",
    "print(\"\\nA) LLM-based Document Summary Retriever:\")\n",
    "print(\"Uses LLM to select relevant documents based on summaries\")\n",
    "try:\n",
    "    nodes_llm = doc_summary_retriever_llm.retrieve(query)\n",
    "    print(f\"Retrieved {len(nodes_llm)} nodes\")\n",
    "    for i, node in enumerate(nodes_llm[:2], 1):\n",
    "        print(f\"{i}. Score: {node.score:.4f}\" if hasattr(node, 'score') and node.score else f\"{i}. (Document summary)\")\n",
    "        print(f\"   Text: {node.text[:80]}...\")\n",
    "        print()\n",
    "except Exception as e:\n",
    "    print(f\"LLM-based retrieval demo: {str(e)[:100]}...\")\n",
    "\n",
    "print(\"B) Embedding-based Document Summary Retriever:\")\n",
    "print(\"Uses vector similarity between query and document summaries\")\n",
    "try:\n",
    "    nodes_emb = doc_summary_retriever_embedding.retrieve(query)\n",
    "    print(f\"Retrieved {len(nodes_emb)} nodes\")\n",
    "    for i, node in enumerate(nodes_emb[:2], 1):\n",
    "        print(f\"{i}. Score: {node.score:.4f}\" if hasattr(node, 'score') and node.score else f\"{i}. (Document summary)\")\n",
    "        print(f\"   Text: {node.text[:80]}...\")\n",
    "        print()\n",
    "except Exception as e:\n",
    "    print(f\"Embedding-based retrieval demo: {str(e)[:100]}...\")\n",
    "\n",
    "print(\"Document Summary Index workflow:\")\n",
    "print(\"1. Generates summaries for each document using LLM\")\n",
    "print(\"2. Uses summaries to select relevant documents\")\n",
    "print(\"3. Returns full content from selected documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371061a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bbeaa1e1",
   "metadata": {},
   "source": [
    "## 4. Auto Merging Retriever - Hierarchical Context Preservation\n",
    "\n",
    "Auto Merging Retriever is designed to preserve context in long documents using a hierarchical structure. **It uses hierarchical chunking to break documents into parent and child nodes, and if enough child nodes from the same parent are retrieved, the retriever returns the parent node instead.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "557a6d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "4. AUTO MERGING RETRIEVER\n",
      "============================================================\n",
      "Query: How do neural networks work in deep learning?\n",
      "Auto-merged to 2 nodes\n",
      "1. Score: 0.8570\n",
      "   Text: Deep learning uses neural networks with multiple layers to model and understand complex patterns in data....\n",
      "\n",
      "2. Score: 0.6956\n",
      "   Text: Supervised learning uses labeled training data to learn a mapping from inputs to outputs....\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"4. AUTO MERGING RETRIEVER\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create hierarchical nodes\n",
    "node_parser = HierarchicalNodeParser.from_defaults(\n",
    "    chunk_sizes=[512, 256, 128]\n",
    ")\n",
    "\n",
    "hier_nodes = node_parser.get_nodes_from_documents(lab.documents)\n",
    "\n",
    "# Create storage context with all nodes\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.core.storage.docstore import SimpleDocumentStore\n",
    "from llama_index.core.vector_stores import SimpleVectorStore\n",
    "\n",
    "docstore = SimpleDocumentStore()\n",
    "docstore.add_documents(hier_nodes)\n",
    "\n",
    "storage_context = StorageContext.from_defaults(docstore=docstore)\n",
    "\n",
    "# Create base index\n",
    "base_index = VectorStoreIndex(hier_nodes, storage_context=storage_context)\n",
    "base_retriever = base_index.as_retriever(similarity_top_k=6)\n",
    "\n",
    "# Create auto-merging retriever\n",
    "auto_merging_retriever = AutoMergingRetriever(\n",
    "    base_retriever, \n",
    "    storage_context,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "query = DEMO_QUERIES[\"advanced\"]  # \"How do neural networks work in deep learning?\"\n",
    "nodes = auto_merging_retriever.retrieve(query)\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"Auto-merged to {len(nodes)} nodes\")\n",
    "for i, node in enumerate(nodes[:3], 1):\n",
    "    print(f\"{i}. Score: {node.score:.4f}\" if hasattr(node, 'score') and node.score else f\"{i}. (Auto-merged)\")\n",
    "    print(f\"   Text: {node.text[:120]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dd2e6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1eefddff",
   "metadata": {},
   "source": [
    "## Recommended Retrievers by Use Case\n",
    "\n",
    "Based on the authoritative source and the characteristics of each retriever, here are recommended approaches for different scenarios:\n",
    "\n",
    "**General Q&A Applications:**\n",
    "- **Primary**: Vector Index Retriever for semantic understanding\n",
    "- **Enhancement**: Combine with BM25 Retriever using Query Fusion for hybrid approach\n",
    "- **Benefit**: Combines semantic relevance with keyword matching\n",
    "- **From authoritative source**: \"For general Q&A, use a vector index retriever, potentially combined with a BM25 retriever. This retriever fusion combines semantic relevance with keyword matching.\"\n",
    "\n",
    "**Technical Documentation:**\n",
    "- **Primary**: BM25 Retriever for exact term matching\n",
    "- **Enhancement**: Vector Index Retriever as secondary for contextual flexibility\n",
    "- **Benefit**: Prioritizes exact technical terms while maintaining semantic understanding\n",
    "- **From authoritative source**: \"For technical documents, especially those where exact terms need to be prioritized, consider making BM25 your primary retriever, with the vector index retriever adding contextual flexibility as a secondary retriever.\"\n",
    "\n",
    "**Long Documents:**\n",
    "- **Primary**: Auto Merging Retriever\n",
    "- **Benefit**: Retrieves longer parent versions only if enough shorter child versions are retrieved, preserving context\n",
    "- **From authoritative source**: \"For long documents, the auto merging retriever is a great option, because it will retrieve longer parent versions only if enough shorter child versions are retrieved.\"\n",
    "\n",
    "**Research Papers:**\n",
    "- **Primary**: Recursive Retriever\n",
    "- **Benefit**: Follows citations and references to retrieve relevant content from cited papers\n",
    "- **From authoritative source**: \"For research papers, use the recursive retriever in order to retrieve relevant content from cited papers.\"\n",
    "\n",
    "**Large Document Collections:**\n",
    "- **Primary**: Document Summary Index Retriever for initial filtering\n",
    "- **Enhancement**: Followed by Vector Index Retriever for detailed search within relevant documents\n",
    "- **Benefit**: Narrows down relevant documents first, then performs detailed retrieval\n",
    "- **From authoritative source**: \"For large document sets, consider using the document summary index retriever to narrow down the number of relevant documents, followed by a vector search within the remaining subset to retrieve the most pertinent content.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efd7cc8",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arf-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
